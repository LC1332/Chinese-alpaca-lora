{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LC1332/luotuo-silk-road.git\n",
        "%cd  luotuo-silk-road/TuoLing\n",
        "!pip install -r requirements.txt "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MYXcSfnHWR1",
        "outputId": "89565a0c-f422-48ab-9ed8-604aca6bc5a2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'luotuo-silk-road'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 22 (delta 5), reused 18 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), 25.97 MiB | 8.01 MiB/s, done.\n",
            "/content/luotuo-silk-road/TuoLing\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/peft.git (from -r requirements.txt (line 14))\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-7nn7udvt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-7nn7udvt\n",
            "  Resolved https://github.com/huggingface/peft.git to commit df71b84341ae1ab3bc9b0d5f906d7a524850b63b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitsandbytes==0.37.1\n",
            "  Downloading bitsandbytes-0.37.1-py3-none-any.whl (76.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.3/76.3 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.17.1\n",
            "  Downloading accelerate-0.17.1-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 KB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20.1,>=3.19.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (3.19.6)\n",
            "Collecting transformers==4.27.1\n",
            "  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting icetk\n",
            "  Downloading icetk-0.0.7-py3-none-any.whl (16 kB)\n",
            "Collecting cpm_kernels==1.0.11\n",
            "  Downloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 KB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (1.13.1+cu116)\n",
            "Collecting datasets==2.10.1\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate==0.17.1->-r requirements.txt (line 3)) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate==0.17.1->-r requirements.txt (line 3)) (5.9.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate==0.17.1->-r requirements.txt (line 3)) (23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate==0.17.1->-r requirements.txt (line 3)) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (3.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 13)) (1.4.4)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 13)) (2023.3.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 13)) (9.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from icetk->-r requirements.txt (line 8)) (0.14.1+cu116)\n",
            "Collecting icetk\n",
            "  Downloading icetk-0.0.6-py3-none-any.whl (15 kB)\n",
            "  Downloading icetk-0.0.5-py3-none-any.whl (15 kB)\n",
            "  Downloading icetk-0.0.4-py3-none-any.whl (15 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.13.1->-r requirements.txt (line 10)) (4.5.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 13)) (22.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 13)) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 13)) (2022.7.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->icetk->-r requirements.txt (line 8)) (8.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.10.1->-r requirements.txt (line 13)) (1.16.0)\n",
            "Building wheels for collected packages: peft\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.3.0.dev0-py3-none-any.whl size=40943 sha256=53776a3cc4e05b7e30c16d426b922c72280ce86b65e7ee0c460859d006e7403d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i62insop/wheels/2d/60/1b/0edd9dc0f0c489738b1166bc1b0b560ee368f7721f89d06e3a\n",
            "Successfully built peft\n",
            "Installing collected packages: tokenizers, sentencepiece, cpm_kernels, bitsandbytes, xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, accelerate, transformers, icetk, aiohttp, peft, datasets\n",
            "Successfully installed accelerate-0.17.1 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 bitsandbytes-0.37.1 cpm_kernels-1.0.11 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.13.3 icetk-0.0.4 multidict-6.0.4 multiprocess-0.70.14 peft-0.3.0.dev0 responses-0.18.0 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.27.1 xxhash-3.2.0 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from modeling_chatglm import ChatGLMForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "\n",
        "torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
        "model = ChatGLMForConditionalGeneration.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True, device_map='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "5877e2a821e74083b0cc0d95255a5bce",
            "7ac693ac61344d1bb521f08b408c7f1b",
            "fbac58de7171444c83061df5b6c85dd9",
            "b30ed02936c7409cb7cad7f15aa561de",
            "43338080fef0469b9fe7321c668bf833",
            "45f31d9298bb428895a36c538d5cc7cf",
            "24554af3fd524739b1088e7fcc3c4426",
            "b681e64b74aa4e1bb8be55740f80d410",
            "e4da2d3a22664b8881fabc7e8eaa9fc3",
            "1040d82db87c4cee898d34f62f056b37",
            "d191aec2e34d4366a2e779f385c0327e"
          ]
        },
        "id": "cFh-odByDQ42",
        "outputId": "5046c816-bc48-44c0-b230-592bb8346336"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5877e2a821e74083b0cc0d95255a5bce"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1ei9dTlDnGq",
        "outputId": "a13f7fbc-a491-481f-a45b-a89d164977e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "peft_path = \"output/luotuoC.pt\"\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM, inference_mode=True,\n",
        "    r=8,\n",
        "    lora_alpha=32, lora_dropout=0.1\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.load_state_dict(torch.load(peft_path), strict=False)\n",
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-icdsX3WsmJ",
        "outputId": "88aa8855-0176-4a9c-e945-2448a7b49288"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/peft/tuners/lora.py:175: UserWarning: fan_in_fan_out is set to True but the target module is not a Conv1D. Setting fan_in_fan_out to False.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This model is a summarization model, you can simply copy your rich text into \"input\" in the next cell. The max input and output sequence length is 2048 currently. Please don't copy input or expect output text longer than this number for accuracy purpose. If you need to train or validate more domain specific data, please contact our team! Thank you!\n",
        "\n",
        "# 本模型为summarization模型，您可以将对应长文本数据，直接复制到下面的输入中。当前模型输入及输出总长度为2048，请复制时不要将大于这个长度的文档放入，以免不准确。如果需要进一步验证数据或训练更多领域相关数据，请随时联系我们团队！谢谢！"
      ],
      "metadata": {
        "id": "vWy1xYDDHbNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cover_alpaca2jsonl import format_example\n",
        "def evaluate(instruction, input=None):\n",
        "  with torch.no_grad():\n",
        "    feature = format_example({'instruction': '请帮我总结以下内容:', 'output': '', 'input': f'{instruction}'})\n",
        "    input_text = feature['context']\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "    out = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=2048,\n",
        "            temperature=0\n",
        "        )\n",
        "    answer = tokenizer.decode(out[0])\n",
        "    print(answer)"
      ],
      "metadata": {
        "id": "mCpwcXqXKn73"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(input(\"您需要总结的长文本请直接复制在这里: \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFMn-HdGIxhn",
        "outputId": "0e620b0e-2a4a-4414-d0cf-170ccfedf7e1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "您需要总结的长文本请直接复制在这里: 美国硅谷银行 (Silicon Valley Bank, SVB ;矽谷银行)和“标志银行”(Signature Bank,又译“签名银行”)在几天内相继倒闭后,美国当局采取了紧急措施来支撑银行系统。这是美国自2008年金融海啸以来最大的银行倒闭事件,恐引起金融市场骨牌效应。硅谷银行因资不抵债在48小时内倒闭后,3月10日由美国联邦存款保险公司(FDIC)接管。美国财政部、联储局及联邦存款保险公司12日晚间发表联合声明指,正采取果断行动,以增强公众对银行体系的信心,并向硅谷银行存户保证,可以在13日周一取回所有存款。3月12日,美国财政部以存在系统性风险为由关闭总部设在纽约州的“标志银行”。该银行是加密货币公司的主要融资来源之一。美国总统拜登发表讲话,承诺将“竭尽所能”保护银行系统。但投资者担心其他银行可能仍会受到影响,引发全球股价大幅下跌。事件震荡全球金融市场,加拿大、英国等多个市场都受牵连。法兰克福、巴黎和米兰的股市大幅下跌。周一(3月13日)早些时候,西班牙桑坦德银行(Santander)和德国商业银行(Commerzbank)的股价一度下跌超过10%。极地资本(Polar Capital)基金经理乔治·戈德伯(George Godber)表示,市场下跌是因为“担心那里可能还有其他事情发生”。他说:“迫在眉睫的危机可能已经避免,但它提醒人们注意这样一个事实,即有一群公司的商业模式将在高利率环境中苦苦挣扎。”但他表示,事件对英国经济和英国市场的直接影响有限。BBC中文梳理这次危机的来龙去脉,以及对全球的影响。\n",
            "美国硅谷银行 (Silicon Valley Bank, SVB ;矽谷银行)和“标志银行”(Signature Bank,又译“签名银行”)在几天内相继倒闭后,美国当局采取了紧急措施来支撑银行系统。这是美国自2008年金融海啸以来最大的银行倒闭事件,恐引起金融市场骨牌效应。硅谷银行因资不抵债在48小时内倒闭后,3月10日由美国联邦存款保险公司(FDIC)接管。美国财政部、联储局及联邦存款保险公司12日晚间发表联合声明指,正采取果断行动,以增强公众对银行体系的信心,并向硅谷银行存户保证,可以在13日周一取回所有存款。3月12日,美国财政部以存在系统性风险为由关闭总部设在纽约州的“标志银行”。该银行是加密货币公司的主要融资来源之一。美国总统拜登发表讲话,承诺将“竭尽所能”保护银行系统。但投资者担心其他银行可能仍会受到影响,引发全球股价大幅下跌。事件震荡全球金融市场,加拿大、英国等多个市场都受牵连。法兰克福、巴黎和米兰的股市大幅下跌。周一(3月13日)早些时候,西班牙桑坦德银行(Santander)和德国商业银行(Commerzbank)的股价一度下跌超过10%。极地资本(Polar Capital)基金经理乔治·戈德伯(George Godber)表示,市场下跌是因为“担心那里可能还有其他事情发生”。他说:“迫在眉睫的危机可能已经避免,但它提醒人们注意这样一个事实,即有一群公司的商业模式将在高利率环境中苦苦挣扎。”但他表示,事件对英国经济和英国市场的直接影响有限。BBC中文梳理这次危机的来龙去脉,以及对全球的影响。\n",
            "Instruction: 请帮我总结以下内容:\n",
            "Input: 美国硅谷银行 (Silicon Valley Bank, SVB ;矽谷银行)和“标志银行”(Signature Bank,又译“签名银行”)在几天内相继倒闭后,美国当局采取了紧急措施来支撑银行系统。这是美国自2008年金融海啸以来最大的银行倒闭事件,恐引起金融市场骨牌效应。硅谷银行因资不抵债在48小时内倒闭后,3月10日由美国联邦存款保险公司(FDIC)接管。美国财政部、联储局及联邦存款保险公司12日晚间发表联合声明指,正采取果断行动,以增强公众对银行体系的信心,并向硅谷银行存户保证,可以在13日周一取回所有存款。3月12日,美国财政部以存在系统性风险为由关闭总部设在纽约州的“标志银行”。该银行是加密货币公司的主要融资来源之一。美国总统拜登发表讲话,承诺将“竭尽所能”保护银行系统。但投资者担心其他银行可能仍会受到影响,引发全球股价大幅下跌。事件震荡全球金融市场,加拿大、英国等多个市场都受牵连。法兰克福、巴黎和米兰的股市大幅下跌。周一(3月13日)早些时候,西班牙桑坦德银行(Santander)和德国商业银行(Commerzbank)的股价一度下跌超过10%。极地资本(Polar Capital)基金经理乔治·戈德伯(George Godber)表示,市场下跌是因为“担心那里可能还有其他事情发生”。他说:“迫在眉睫的危机可能已经避免,但它提醒人们注意这样一个事实,即有一群公司的商业模式将在高利率环境中苦苦挣扎。”但他表示,事件对英国经济和英国市场的直接影响有限。BBC中文梳理这次危机的来龙去脉,以及对全球的影响。\n",
            "Answer: 硅谷银行和“标志银行”倒闭,美国当局采取紧急措施支撑银行系统,全球股市大幅下跌。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(input(\"Put your rich text here which you want to summarize it: \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGnbWNW2NPNG",
        "outputId": "5d20309f-ab0e-4741-a8f0-fe9c702cd058"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Put your rich text here which you want to summarize it: 第二次世界大战之后，美国是无可争辩的世界头号经济体，并且它相信自己在军事上也同样无可匹敌。然而在越南，美国尽管投入了大量的资金和人力，但是在经过至少八年的战斗之后还是被北越及其游击队同盟越南南方民族解放阵线（Viet Cong，惯称“越共”）所打败。3月29日是美国从越南最终撤军的50周年，我们访问了两位专家学者，了解美国到底是如何在越南战争中落败。 那是正值冷战时代的高峰，共产主义和资本主义大国正在全球展开对抗。 被二战拖垮至破产的法国曾试图保住他们在中南半岛（Indochina，另称“印度支那”）的殖民地未果，然后一场和平的会议中将如今的越南分割成北边的共产主义政权和南边由美国扶植的政府。 但是法国人的败退并未终结越南国内的冲突，而美国害怕一旦越南全国成为共产主义政权，那么它周边的国家也会一样。美国就是在这种恐惧的驱动下，卷入了一场持续十年并夺去数以百万计生命的战争。\n",
            "第二次世界大战之后，美国是无可争辩的世界头号经济体，并且它相信自己在军事上也同样无可匹敌。然而在越南，美国尽管投入了大量的资金和人力，但是在经过至少八年的战斗之后还是被北越及其游击队同盟越南南方民族解放阵线（Viet Cong，惯称“越共”）所打败。3月29日是美国从越南最终撤军的50周年，我们访问了两位专家学者，了解美国到底是如何在越南战争中落败。 那是正值冷战时代的高峰，共产主义和资本主义大国正在全球展开对抗。 被二战拖垮至破产的法国曾试图保住他们在中南半岛（Indochina，另称“印度支那”）的殖民地未果，然后一场和平的会议中将如今的越南分割成北边的共产主义政权和南边由美国扶植的政府。 但是法国人的败退并未终结越南国内的冲突，而美国害怕一旦越南全国成为共产主义政权，那么它周边的国家也会一样。美国就是在这种恐惧的驱动下，卷入了一场持续十年并夺去数以百万计生命的战争。\n",
            "Instruction: 请帮我总结以下内容:\n",
            "Input: 第二次世界大战之后,美国是无可争辩的世界头号经济体,并且它相信自己在军事上也同样无可匹敌。然而在越南,美国尽管投入了大量的资金和人力,但是在经过至少八年的战斗之后还是被北越及其游击队同盟越南南方民族解放阵线(Viet Cong,惯称“越共”)所打败。3月29日是美国从越南最终撤军的50周年,我们访问了两位专家学者,了解美国到底是如何在越南战争中落败。 那是正值冷战时代的高峰,共产主义和资本主义大国正在全球展开对抗。 被二战拖垮至破产的法国曾试图保住他们在中南半岛(Indochina,另称“印度支那”)的殖民地未果,然后一场和平的会议中将如今的越南分割成北边的共产主义政权和南边由美国扶植的政府。 但是法国人的败退并未终结越南国内的冲突,而美国害怕一旦越南全国成为共产主义政权,那么它周边的国家也会一样。美国就是在这种恐惧的驱动下,卷入了一场持续十年并夺去数以百万计生命的战争。\n",
            "Answer: 美国在越南战争中被北越打败,原因有多方面:1、法国殖民者败退,美国卷入战争;2、越南国内冲突,美国害怕周边国家也遭同样的命运;3、越南人民军实力强大,美国难以抵挡。\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "25273a2a68c96ebac13d7fb9e0db516f9be0772777a0507fe06d682a441a3ba7"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5877e2a821e74083b0cc0d95255a5bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ac693ac61344d1bb521f08b408c7f1b",
              "IPY_MODEL_fbac58de7171444c83061df5b6c85dd9",
              "IPY_MODEL_b30ed02936c7409cb7cad7f15aa561de"
            ],
            "layout": "IPY_MODEL_43338080fef0469b9fe7321c668bf833"
          }
        },
        "7ac693ac61344d1bb521f08b408c7f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45f31d9298bb428895a36c538d5cc7cf",
            "placeholder": "​",
            "style": "IPY_MODEL_24554af3fd524739b1088e7fcc3c4426",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fbac58de7171444c83061df5b6c85dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b681e64b74aa4e1bb8be55740f80d410",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4da2d3a22664b8881fabc7e8eaa9fc3",
            "value": 8
          }
        },
        "b30ed02936c7409cb7cad7f15aa561de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1040d82db87c4cee898d34f62f056b37",
            "placeholder": "​",
            "style": "IPY_MODEL_d191aec2e34d4366a2e779f385c0327e",
            "value": " 8/8 [00:12&lt;00:00,  1.35s/it]"
          }
        },
        "43338080fef0469b9fe7321c668bf833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45f31d9298bb428895a36c538d5cc7cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24554af3fd524739b1088e7fcc3c4426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b681e64b74aa4e1bb8be55740f80d410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4da2d3a22664b8881fabc7e8eaa9fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1040d82db87c4cee898d34f62f056b37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d191aec2e34d4366a2e779f385c0327e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}