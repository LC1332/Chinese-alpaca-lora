# 骆驼Tokenizer的计划

## 动机

+ 原来的LLaMA中文支持能力差

+ 并入中文的tokenizer和原空间不对齐，重训大量知识会混乱

+ 我们希望有一个中文支持更好的tokenizer，还是和原来的LLaMA对齐

## 目标

我们希望我们的Tokenizer有下面这些特征

+ 首先是空间对齐，比如"铁"这个字，和英语的"iron"能够在LLaMA原来的空间上对齐

+ 能够使用四角编码/五笔编码，泛化到任意的汉字

+ 高频的汉字能有独立的token，并且根据其高频的一些词汇，确定在LLaMA上对应的向量

+ 低频的汉字能够组织成四角编码/五笔编码，并且偏旁部首也获得合理的embedding。比如金字旁就会来源于铜、铁等字的平均，这样当模型面对锎、镧这些低频字的时候，就会有办法处理。

+ 我们希望有两个token，一个在llama的基础上只增不减，一个还是删除一些英语的token，使得colab普通机器也可以载入这个tokenizer

## 可能使用到的工具

+ 四角编码

## 要注意到的问题

+ 要注意

## 检验方法


##